# 第八章 数据规整：聚合、合并和重塑（Data Wrangling: Join, Combine）

数据可能分散在许多⽂件或数据库中，存储的形式也不利于分析。本章深⼊介绍了⼀些特殊的数据操作。

## 8.1 层次化索引（Hierarchical Indexing）

#### 1.层次化索引基本操作

层次化索引（hierarchical indexing）是pandas的⼀项重要功能，它使你能在⼀个轴上拥有多个（两个以上）索引级别。抽象点说，它使你能以低维度形式处理⾼维度数据。

`index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],[1, 2, 3, 1, 3, 1, 2, 2, 3]]`

~~~python
data = pd.Series(np.random.randn(9),
                 index=[['a', 'a', 'a', 'b', 'b', 'c', 'c', 'd', 'd'],
                        [1, 2, 3, 1, 3, 1, 2, 2, 3]])
data.index
#看到的结果是经过美化的带有MultiIndex索引的Series的格式
data['b']
data['b':'c']
data.loc[['b', 'd']]
#有时甚⾄还可以在“内层”中进⾏选取
data.loc[:, 2]
~~~

:spider_web:对于⼀个层次化索引的对象，可以使⽤所谓的部分索引，使⽤它选取数据子集的操作（**索引切片**）更简单。（其实这个好像用处也不大）

层次化索引在数据重塑和基于分组的操作（如**透视表**⽣成）中扮演着重要的⻆⾊。可以通过`unstack` 方法将这段数据重新安排到⼀个DataFrame中。unstack的逆运算是stack。

~~~python
data.unstack()
data.unstack().stack()
~~~

___

⼀个DataFrame，每条轴都可以有分层索引

~~~python
frame = pd.DataFrame(np.arange(12).reshape((4, 3)),\
                     index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\
                     columns=[['Ohio', 'Ohio', 'Colorado'],\
                              ['Green', 'Red', 'Green']])
frame.index.names = ['key1', 'key2']
frame.columns.names = ['state', 'color']
frame
frame['Ohio']
~~~

> ⼩⼼区分索引名state、color与⾏标签

#### 2.重排与分级排序（Reordering and Sorting Levels）

需要重新调整某条轴上各级别的顺序，或根据指定级别上的值对数据进⾏排序。swaplevel接受两个级别编号或名称，并返回⼀个互换了级别的新对象（但数据不会发⽣变化）。

`swaplevel()`和 `sort_index（）`

~~~python
frame = pd.DataFrame(np.arange(12).reshape((4, 3)),\
                     index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\
                     columns=[['Ohio', 'Ohio', 'Colorado'],\
                              ['Green', 'Red', 'Green']])
frame.index.names = ['key1', 'key2']
frame.columns.names = ['state', 'color']
frame.sort_index(level=1)
#两者联立使用（感觉只限两列），用处不大
frame.swaplevel(0, 1).sort_index(level=0)
~~~

#### 3.根据级别汇总统计（Summary Statistics by Level）

`sum()`

许多对DataFrame和Series的**描述和汇总统计**都有⼀个level选项，它⽤于**指定在某条轴上求和的级别**。

~~~python
frame = pd.DataFrame(np.arange(12).reshape((4, 3)),\
                     index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],\
                     columns=[['Ohio', 'Ohio', 'Colorado'],\
                              ['Green', 'Red', 'Green']])
frame.index.names = ['key1', 'key2']
frame.columns.names = ['state', 'color']
frame.sum(level='key2')
frame.sum(level='color', axis=1)
#取层次化索引中['a','Green']中值的总和
z=frame.sum(level='color',axis=1)
z.loc['a','Green'].sum()
~~~

:spider_web:level 层次（我们老师经常说的level水平、层级）

#### 4.使⽤DataFrame的列进⾏索引（Indexing with a DataFrame's columns）

将DataFrame的⼀个或多个列当做⾏索引来⽤，或者可能希望将⾏索引变成DataFrame的列。（我就经常遇到这种情况）

  `set_index()`  DataFrame的set_index函数会将其⼀个或多个列转换为⾏索引，并创建⼀个新的DataFrame

~~~python
frame = pd.DataFrame({'a': range(7), 'b': range(7, 0, -1),
                      'c': ['one', 'one', 'one', 'two', 'two',
                            'two', 'two'],
                      'd': [0, 1, 2, 0, 1, 2, 3]})
frame
frame2 = frame.set_index(['c', 'd'])
frame2
frame.set_index(['c', 'd'], drop=False)
frame2.reset_index()
~~~

:spider_web:默认情况下，那些列会从DataFrame中移除，但也可以将其保留下来(其中的某个属性设置为drop=False)

:spider_web:**set_index()和reset_index()的区别**：set_index函数会将其⼀个或多个列转换为行索引，而reset_index()是层次化索引的级别转移到列。两者区别要牢记！建议使用reset_index()来重设列索引。

## 8.2 合并数据集（Combining and Merging Datasets）

* pandas.merge可根据⼀个或多个键将不同DataFrame中的⾏连接起来。SQL或其他关系型数据库的⽤户对此应该会⽐较
  熟悉，因为它实现的就是数据库的join操作。
* pandas.concat可以沿着⼀条轴将多个对象堆叠到⼀起。
* 实例⽅法combine_first可以将重复数据编接在⼀起，⽤⼀个对象中的值填充另⼀个对象中的缺失值。

#### 1.数据库⻛格的DataFrame合并（Database-Style DataFrame Joins）

数据集的合并（merge）或连接（join）运算是通过⼀个或多个键将⾏链接起来的。

`merge()`  和    `join()`

~~~python
df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],
                    'data1': range(7)})
df2 = pd.DataFrame({'key': ['a', 'b', 'd'],
                    'data2': range(3)})
df1
df2
#没有指明要⽤哪个列进⾏连接。如果没有指定，merge就会将重叠列的列名当做键。
pd.merge(df1,df2, on='key')
#默认情况下，merge做的是“内连接”；结果中的键是交集。其他⽅式还有"left"、"right"以及"outer"。
pd.merge(df1, df2, how='outer')
#_________________________________________________________________
df3 = pd.DataFrame({'lkey': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],
                    'data1': range(7)})
df4 = pd.DataFrame({'rkey': ['a', 'b', 'd'],
                    'data2': range(3)})
pd.merge(df3, df4, left_on='lkey', right_on='rkey')
~~~

![1](F:\github_desktop\github文件路径\books\python-for-data-analysis_2nd\Chapter 8 pictures\1.png)

多对多连接产⽣的是⾏的笛卡尔积

~~~python
df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'b'],
                    'data1': range(6)})
df2 = pd.DataFrame({'key': ['a', 'b', 'a', 'b', 'd'],
                    'data2': range(5)})
df1
df2
#⾏的笛卡尔积
pd.merge(df1, df2, on='key', how='left')
pd.merge(df1, df2, how='inner')
pd.merge(df1, df2, how='outer')
~~~

:spider_web:注意二者的区别：on表示以DataFrame中的那一列作为索引（类似于交集），而how表示所有类型值（类似于并集）

![2](F:\github_desktop\github文件路径\books\python-for-data-analysis_2nd\Chapter 8 pictures\2.png)

#### 2.索引上的合并（Merging on Index）

DataFrame中的连接键位于其索引中。在这种情况下，你可以传⼊left_index=True或right_index=True（或两个都传）以说明索引应该被⽤作连接键。（小例子：比如说两个表的时间序列的拼接）

~~~python
left1 = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],
                      'value': range(6)})
right1 = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])
left1
right1
pd.merge(left1, right1, left_on='key', right_index=True)
~~~

DataFrame还有⼀个便捷的join实例⽅法，它能更为⽅便地实现按索引合并。它还可⽤于合并多个带有**相同或相似索引**的DataFrame对象，但要求没有重叠的列。

~~~python
left2 = pd.DataFrame([[1., 2.], [3., 4.], [5., 6.]],
                     index=['a', 'c', 'e'],
                     columns=['Ohio', 'Nevada'])
right2 = pd.DataFrame([[7., 8.], [9., 10.], [11., 12.], [13, 14]],
                      index=['b', 'c', 'd', 'e'],
                      columns=['Missouri', 'Alabama'])
left2.join(right2, how='outer')
#________________________________________________
left1 = pd.DataFrame({'key': ['a', 'b', 'a', 'a', 'b', 'c'],
                      'value': range(6)})
right1 = pd.DataFrame({'group_val': [3.5, 7]}, index=['a', 'b'])
left1.join(right1, on='key')
~~~

结果如下：

|      | key  | value | group_val |
| :--: | :--: | :---: | :-------: |
|  0   |  a   |   0   |    3.5    |
|  1   |  b   |   1   |    7.0    |
|  2   |  a   |   2   |    3.5    |
|  3   |  a   |   3   |    3.5    |
|  4   |  b   |   4   |    7.0    |
|  5   |  c   |   5   |    NaN    |

#### 3.轴向连接（Concatenating Along an Axis）

数据合并运算也被称作连接（concatenation）、绑定（binding）或堆叠（stacking）。

pandas的concat函数提供了⼀种能够解决很多问题的可靠⽅式。

神奇的concat！

~~~python
s1 = pd.Series([0, 1], index=['a', 'b'])
s2 = pd.Series([2, 3, 4], index=['c', 'd', 'e'])
s3 = pd.Series([5, 6], index=['f', 'g'])
pd.concat([s1, s2, s3])
pd.concat([s1, s2, s3], axis=1)

#多个series合并，使用keys可以区分拼接的数据来自哪里（定义数据的来源）
result = pd.concat([s1, s1, s3], keys=['one', 'two', 'three'])
result
result.unstack()
#多个series合并，使用keys可以区分拼接的数据来自哪里（定义数据的来源） 层次化索引运用
df1 = pd.DataFrame(np.arange(6).reshape(3, 2), index=['a', 'b', 'c'],
                   columns=['one', 'two'])
df2 = pd.DataFrame(5 + np.arange(4).reshape(2, 2), index=['a', 'c'],
                   columns=['three', 'four'])
df1
df2
oof=pd.concat([df1, df2], axis=1, keys=['level1', 'level2'])
#pd.concat({'level1': df1, 'level2': df2}, axis=1)  与上述表达一致
#pd.concat([df1, df2], axis=1, keys=['level1', 'level2'],names=['upper', 'lower']) 与上述表达一致
print(oof)
oof1=oof.unstack()
oof2=oof.unstack()
~~~

DataFrame的⾏索引不包含任何相关数据

~~~python
df1 = pd.DataFrame(np.random.randn(3, 4), columns=['a', 'b', 'c', 'd'])
df2 = pd.DataFrame(np.random.randn(2, 3), columns=['b', 'd', 'a'])
#⾏索引不包含任何相关数据
pd.concat([df1, df2], ignore_index=True)
~~~

![3](F:\github_desktop\github文件路径\books\python-for-data-analysis_2nd\Chapter 8 pictures\3.png)

#### 4.合并重叠数据（Combining Data with Overlap）

有⼀种数据组合问题不能⽤简单的合并（merge）或连接（concatenation）运算来处理。你可能有索引全部或部分重叠的两个数据集。

`where`        `combine_first`

~~~python
a = pd.Series([np.nan, 2.5, np.nan, 3.5, 4.5, np.nan],
              index=['f', 'e', 'd', 'c', 'b', 'a'])
b = pd.Series(np.arange(len(a), dtype=np.float64),
              index=['f', 'e', 'd', 'c', 'b', 'a'])
b[-1] = np.nan
#np中方法可以用来处理series
np.where(pd.isnull(a), b, a)
#重叠数据的取值，然后生成一列添加到表就可以了
b[:-2].combine_first(a[2:])
#————————————————————————————————————————————
df1 = pd.DataFrame({'a': [1., np.nan, 5., np.nan],
                    'b': [np.nan, 2., np.nan, 6.],
                    'c': range(2, 18, 4)})
df2 = pd.DataFrame({'a': [5., 4., np.nan, 3., 7.],
                    'b': [np.nan, 3., 4., 6., 8.]})
df1.combine_first(df2)
~~~

## 8.3重塑和轴向旋转（Reshaping and Pivoting）

有许多⽤于重新排列表格型数据的基础运算。重塑（reshape）或轴向旋转（pivot）运算。

#### 1. 重塑层次化索引 （Reshaping with Hierarchical Indexing）

层次化索引为DataFrame数据的重排任务（通俗的理解为转置）

* stack：将数据的列“旋转”为⾏。
* unstack：将数据的⾏“旋转”为列。

传⼊分层级别的编号或名称即可对其它级别进⾏unstack操作。

~~~python
s1 = pd.Series([0, 1, 2, 3], index=['a', 'b', 'c', 'd'])
s2 = pd.Series([4, 5, 6], index=['c', 'd', 'e'])
data2 = pd.concat([s1, s2], keys=['one', 'two'])
data2
data2.unstack()
~~~

调⽤stack，我们可以指明轴的名字：

~~~python
data = pd.DataFrame(np.arange(6).reshape((2, 3)),
                    index=pd.Index(['Ohio', 'Colorado'], name='state'),
                    columns=pd.Index(['one', 'two', 'three'],
                    name='number'))
result = data.stack()
df = pd.DataFrame({'left': result, 'right': result + 5},
                  columns=pd.Index(['left', 'right'], name='side'))
df
df.unstack('state')
#state轴不旋转；而side轴旋转
df.unstack('state').stack('side')
~~~

#### 2.将“长格式”旋转为“宽格式”（Pivoting “Long” to “Wide” Format）

没什么好说的，直接上代码，实际操作，好好看，好好学！[文件](F:/github_desktop/github文件路径/books/python-for-data-analysis_2nd/examples/macrodata.csv)

~~~python
data = pd.read_csv('examples/macrodata.csv')
data.head()
periods = pd.PeriodIndex(year=data.year, quarter=data.quarter,
                         name='date')
columns = pd.Index(['realgdp', 'infl', 'unemp'], name='item')
data = data.reindex(columns=columns)
data.index = periods.to_timestamp('D', 'end')
ldata = data.stack().reset_index().rename(columns={0: 'value'})
#上述stack的实际应用
pivoted = ldata.pivot('date', 'item', 'value')
#上述再旋转
#增加一列
ldata['value2'] = np.random.randn(len(ldata))
#忽略最后⼀个参数，得到的DataFrame就会带有层次化的列
pivoted1 = ldata.pivot('date', 'item')
#上下二者等价（pivot其实就是⽤set_index创建层次化索引，再⽤unstack重塑）
unstacked = ldata.set_index(['date', 'item']).unstack('item')

pivoted1[:5]
pivoted1['value'][:5]
~~~

:spider_web:上下二者等价（pivot其实就是⽤set_index创建层次化索引，再⽤unstack重塑）

#### 4.将“宽格式”旋转为“⻓格式”(Pivoting “Wide” to “Long” Format)

傻话也别说，直接代码

`melted()`

~~~python
df = pd.DataFrame({'key': ['foo', 'bar', 'baz'],
                   'A': [1, 2, 3],
                   'B': [4, 5, 6],
                   'C': [7, 8, 9]})
#Pivoting “Wide” to “Long” Format
melted = pd.melt(df, ['key'])
melted
#contrary
reshaped = melted.pivot('key', 'variable', 'value')
reshaped
reshaped.reset_index()
#只选取A B
pd.melt(df, id_vars=['key'], value_vars=['A', 'B'])
#
pd.melt(df, value_vars=['A', 'B', 'C'])
pd.melt(df, value_vars=['key', 'A', 'B'])
~~~

