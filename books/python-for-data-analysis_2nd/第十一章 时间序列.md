[TOC]



# 时间序列（time series）

时间序列（time series）数据是⼀种重要的结构化数据形式，应⽤于多个领域，包括⾦融学、经济学、⽣态学、神经科学、物理学等。在**多个时间点观察或测量到的任何事物都可以形成⼀段时间序列**。

* 时间戳（timestamp），特定的时刻。
* 固定时期（period），如2007年1⽉或2010年全年。
* 时间间隔（interval），由起始和结束时间戳表示。时期（period）可以被看做间隔（interval）的特例。(**这个地方在很多案例中非常常用**)
* 实验或过程时间，每个时间点都是相对于特定起始时间的⼀个度量。例如，从放⼊烤箱时起，每秒钟饼⼲的直径。

> pandas也⽀持基于timedeltas的指数（第四种情况），它可以有效代表实验或经过的时间。这本书不涉及timedelta指数，但你可以学习pandas的⽂档（http://pandas.pydata.org/）,3千多页的参考文档，我想我不会去看的。可以当作资料进行查阅。

你可以⾼效处理⾮常⼤的时间序列，轻松地进⾏切⽚/切块、聚合、对定期/不定期的时间序列进⾏重采样等。

~~~mermaid
graph TD
id1[时间序列] --> id2[金融和经济应用]
id1[时间序列] --> id3[服务器日志数据]
id1[时间序列] --> id4[科研]
~~~

## 11.1 日期和时间数据类型及工具(Date and Time Data Types and Tools)

Python标准库包含⽤于⽇期（date）和时间（time）数据的数据类型，⽽且还有日历方面的功能。我们主要会⽤到datetime、time以及calendar模块。

datetime.datetime（也可以简写为datetime）是⽤得最多的数据类型。datetime以毫秒形式存储日期和时间。

datetime模块中的数据类型有date、time、datetime以及timedelta（两个datetime值之间的差）。

~~~python
from datetime import datetime
now = datetime.now()
delta = datetime(2011, 1, 7) - datetime(2008, 6, 24, 8, 15)
delta
#delta有year、month、day、hour、second
delta.days
delta.seconds

start = datetime(2011, 1, 7)
start - timedelta(12)
~~~

#### 字符串和datetime的相互转换（Converting Between String and Datetime）

利⽤str或strftime⽅法（传⼊⼀个格式化字符串），**datetime**对象和pandas的**Timestamp**对象（稍后就会介绍）可以被格式化为字符串。

`strftime`、`strptime`、`parse`、`to_datetime`

~~~python
from datetime import timedelta
stamp = datetime(2011, 1, 3)
#两种方式：datetime转换为str
str(stamp)
stamp.strftime('%Y-%m-%d')
#str转换为datetime（datetime.strptime是通过已知格式进⾏⽇期解析的最佳⽅式。）或者parser
value = '2011-01-03'
datetime.strptime(value, '%Y-%m-%d')
datestrs = ['7/6/2011', '8/6/2011']
[datetime.strptime(x, '%m/%d/%Y') for x in datestrs]

from dateutil.parser import parse
parse('2011-01-03'),parse('Jan 31, 1997 10:45 PM')

parse('6/12/2011', dayfirst=True)
#to_datetime⽅法可以解析多种不同的⽇期表示形式。
datestrs = ['2011-07-06 12:00:00', '2011-08-06 00:00:00']

pd.to_datetime(datestrs)
idx = pd.to_datetime(datestrs + [None])
pd.isnull(idx)
~~~

下面一表是str解析为datetime的格式设置

<img src="F:\github_desktop\github文件路径\books\python-for-data-analysis_2nd\chapter 11 pictures\1.png" alt="1" style="zoom:50%;" />

:spider_web:datetime转换为str两种方式：str或strftime⽅法

:spider_web:str转换为datetime两种方法：datetime.strptime或者parser

:spider_web:注意：dateutil.parser是⼀个实⽤但不完美的⼯具。⽐如说，它会把⼀些原本不是⽇期的字符串认作是⽇期（⽐如"42"会被解析为2042年的今天）。

下面一表是datetime解析为str的格式设置

<img src="F:\github_desktop\github文件路径\books\python-for-data-analysis_2nd\chapter 11 pictures\2.png" alt="2" style="zoom:50%;" />

## 11.2 时间序列基础（Time Series Basics）

pandas最基本的时间序列类型就是以**时间戳（timestamp）**（通常以Python字符串或datatime对象表示）为索引的Series。这些datetime对象实际上是被放在⼀个**DatetimeIndex**中。

DatetimeIndex中的各个标量值是pandas的Timestamp对象（datetime）。只要有需要，TimeStamp可以随时⾃动转换为datetime对象。

~~~python
from datetime import datetime
dates = [datetime(2011, 1, 2), datetime(2011, 1, 5),
         datetime(2011, 1, 7), datetime(2011, 1, 8),
         datetime(2011, 1, 10), datetime(2011, 1, 12)]
ts = pd.Series(np.random.randn(6), index=dates)
ts.index
#DatetimeIndex(['2011-01-02', '2011-01-05', '2011-01-07', '2011-01-08',
#               '2011-01-10', '2011-01-12'],
#              dtype='datetime64[ns]', freq=None)

~~~

#### 索引、选取、子集构造(Indexing, Selection, Subsetting)

传⼊⼀个可以被解释为日期的字符串（**加入loc，可能更好**）

~~~python
longer_ts = pd.Series(np.random.randn(1000),
                      index=pd.date_range('1/1/2000', periods=1000))
longer_ts
longer_ts['2001']
#索引找值
longer_ts[longer_ts.index[2]]
#直接传入可以被解释为日期的字符串
longer_ts['1/10/2011']
longer_ts['20110110']
longer_ts['2001-05']
#datetime对象进行切片操作
longer_ts[datetime(2002, 1, 7):]
#类似上述的操作
longer_ts.truncate(after='1/7/2002')

longer_ts['1/6/2001':'1/11/2001']
~~~

:spider_web:日期索引找值的方法太给力了吧，非常实用。

:spider_web:longer_ts[datetime(2002, 1, 7):]和longer_ts.truncate(after='1/7/2002')的操作是一样的

~~~python
dates = pd.date_range('1/1/2000', periods=100, freq='W-WED')
long_df = pd.DataFrame(np.random.randn(100, 4),
                       index=dates,
                       columns=['Colorado', 'Texas',
                                'New York', 'Ohio'])
long_df.loc['5-2001']
~~~

:spider_web:上述的时间序列设置可以发现freq是设置时间间隔（以最开始的星期天到整个时间序列的星期天）。常见的有W、H、Y

#### 带有重复索引的时间序列（Time Series with Duplicate Indices）

~~~python
dates = pd.DatetimeIndex(['1/1/2000', '1/2/2000', '1/2/2000',
                          '1/2/2000', '1/3/2000'])
dup_ts = pd.Series(np.arange(5), index=dates)
dup_ts
dup_ts.index.is_unique
dup_ts['1/3/2000']  # not duplicated
dup_ts['1/2/2000']  # duplicated
#分组操作
#对具有⾮唯⼀时间戳的数据进⾏聚合。⼀个办法是使⽤groupby，并传⼊level=0
grouped = dup_ts.groupby(level=0)
grouped.mean()
grouped.count()
~~~

## 11.3 日期的范围、频率以及移动（Date Ranges, Frequencies, and Shifting）

它常常需要以某种相对固定的频率进⾏分析，⽐如每⽇、每⽉、每15分钟等（这样⾃然会在时间序列中引⼊缺失值）。幸运的是，pandas有⼀整套标准时间序列频率以及⽤于重采样、频率推断、⽣成固定频率⽇期范围的⼯具。

在11.6小节中着重来探讨日期的频率转换（重采样）

#### ⽣成日期范围（Generating Date Ranges）

生成日期范围前面一直在用。

`date_range` 

pandas.date_range可⽤于根据指定的频率⽣成指定⻓度的DatetimeIndex

~~~python
import pandas as pd
index = pd.date_range('2012-04-01', '2012-06-01')
pd.date_range(start='2012-04-01', periods=20)
pd.date_range(end='2012-06-01', periods=20)
#freq为BM，表示为在start至end之间的Month的最后一天
pd.date_range('2000-01-01', '2000-12-01', freq='BM')

pd.date_range('2012-05-02 12:56:31', periods=5, normalize=True)
~~~

:spider_web:下面是基本的时间序列频率（不完整），只列举一些常用的生成指定频率的日期间隔（date_range默认会保留起始和结束时间戳的时间信息（如果有的话））。

| 别名                | 偏移量类型           | 说明                                                         |
| ------------------- | -------------------- | ------------------------------------------------------------ |
| **D**               | **Day**              | **每日历日**                                                 |
| B                   | BusinessDay          | 每工作日                                                     |
| H                   | Hour                 | 每小时                                                       |
| **T/min**           | Minute               | 每分                                                         |
| S                   | Second               | 每秒                                                         |
| L/ms                | Million              | 每毫秒                                                       |
| U                   | Micro                | 每微妙                                                       |
| M                   | MonthEnd             | 每月最后一个日历日                                           |
| BM                  | BusinessMonthEnd     | 每月最后一个工作日                                           |
| MS                  | MonthBegin           | 每月第一个日历日                                             |
| BMS                 | BusinessMonthBegin   | 每月第一个工作日                                             |
| **W-MON、W-TUE…**   | **Week**             | **从指定的星期几（MON、TUE、WED、THU、FRI、SAT、SUN）开始算起，每周** |
| WOM-1MON、WOM-2MON… | WeekOfMonth          | 产生每月第一、二、三、四周的星期几，例如WOM-1MON表示每月的第一个星期一 |
| Q-JAN、Q-FEB…       | QuarterEnd           | 对于以指定月份（JAN、FEB、…、DEC）结束的年度，每季度的最后一月的最后一个日历日 |
| BQ-JAN、BQ-FEB…     | BusinessQuarterEnd   | 对于以指定月份（JAN、FEB、…、DEC）结束的年度，每季度的最后一月的最后一个工作日 |
| **QS-JAN、QS-FEB…** | **QuarterBegin**     | **对于以指定月份（JAN、FEB、…、DEC）结束的年度，每季度的最后一月的第一个日历日** |
| BQS-JAN、BQS-FEB…   | BusinessQuarterBegin | 对于以指定月份（JAN、FEB、…、DEC）结束的年度，每季度的最后一月的第一个工作日 |
| A-JAN、A-FEB…       | YearEnd              | 每年指定月份最后一个日历日                                   |
| BA-JAN、BA-FEB…     | BusinessYearEnd      | 每年指定月份最后一个工作日                                   |
| AS-JAN、AS-FEB…     | YearBegin            | 每月指定月份第一个日历日                                     |
| BAS-JAN、BAS-FEB…   | BusinessYearBegin    | 每月指定月份第一个工作日                                     |

:spider_web:起始和结束日期带有时间信息，但你希望产⽣⼀组被规范化（normalize）的时间戳（年月日）。

#### 频率和日期偏移量（Frequencies and Date Offsets)

pandas中的频率是由⼀个基础频率（base frequency）和⼀个乘数组成的。

~~~python
pd.date_range('2000-01-01', periods=10, freq='1h30min')
~~~

#### WOM日期(Week of month dates)

WOM（Week Of Month）是⼀种⾮常实用的频率类，它以WOM开头。它使你能获得诸如“**每月第3个星期五**”之类的日期。

~~~python
rng = pd.date_range('2012-01-01', '2012-09-01', freq='WOM-3FRI')
list(rng)
wom=pd.date_range('2020/8/17','2020/12/31',freq='WOM-1MON')
wom
~~~

#### 移动（超前和滞后）数据（Shifting (Leading and Lagging) Data）

移动（shifting）指的是沿着时间轴将数据前移或后移。Series和DataFrame都有⼀个shift⽅法⽤于执⾏单纯的前移或后移操作，保持索引不变。

只是移动数据，在时间序列处理时经常用到（shift通常⽤于计算⼀个时间序列或多个时间序列（如DataFrame的列）中的百分⽐变化）。

~~~python
ts = pd.Series(np.random.randn(4),
               index=pd.date_range('1/1/2000', periods=4, freq='M'))
ts
ts.shift(2)
ts.shift(-2)
#DatetimeIndex(['2000-01-31', '2000-02-29', '2000-03-31', '2000-04-#30'], dtype='datetime64[ns]', freq='M')
ts.shift(2, freq='M')
#2000-03-31    0.769023
#2000-04-30    1.246435
#2000-05-31    1.007189
#2000-06-30   -1.296221
#Freq: M, dtype: float64
ts.shift(3, freq='D')
ts.shift(1, freq='90T')
#补充内容：计算一个时间系列的百分比变化
pct_ts=ts / ts.shift(1) - 1
pct_ts
~~~

#### 通过偏移量对日期进行位移（Shifting dates with offsets）

`from pandas.tseries.offsets import Day, MonthEnd` 中亦可以实现日期的偏移

~~~python
from pandas.tseries.offsets import Day, MonthEnd
from datetime import datetime
now = datetime(2011, 11, 17)
now + 3 * Day()
#锚点偏移量（⽐如MonthEnd）
now + MonthEnd()
#Timestamp('2011-11-30 00:00:00')
now + MonthEnd(2)
#通过锚点偏移量的rollforward和rollback⽅法，可明确地将⽇期向前或向后“滚动”
offset = MonthEnd()
offset.rollforward(now)
offset.rollback(now)

#这个方法没啥用的
ts = pd.Series(np.random.randn(20),
               index=pd.date_range('1/15/2000', periods=20, freq='4d'))
ts
ts.groupby(MonthEnd().rollforward).mean()
#和上述方法一样
ts.resample('M').mean()
~~~

## 11.4 时区处理（Time Zone Handling）

**时间序列处理工作**中最让⼈不爽的就是对时区的处理。许多⼈都选择以协调世界时（UTC，它是格林尼治标准时间（GreenwichMean Time）的接替者，⽬前已经是国际标准了）来处理时间序列。时区是以UTC偏移量的形式表示的。

**UTC和GMT时间**

在Python中，时区信息来⾃**第三⽅库pytz**，它使Python可以使⽤Olson数据库（汇编了世界时区信息）。这对历史数据⾮常重要，这是因为由于各地政府的各种突发奇想，夏令时转变⽇期（甚⾄UTC偏移量）已经发⽣过多次改变了。

pandas包装了pytz的功能，因此你可以不⽤记忆其API，只要记得时区的名称即可。

~~~python
import pytz
pytz.common_timezones[-5:]

pytz.country_timezones('cn')
#关于北京时间。在pytz中，我无法找到Asia/Beijing和GMT+8这样的时区设置，但是有些时间转换的工具却有。按理说pytz使用的是标准的时区数据库，我特意下载了查看，的确是没有。
tz = pytz.timezone('America/New_York')
tz
~~~

#### 时区本地化和转换（Time Zone Localization and Conversion）

默认情况下，pandas中的时间序列是单纯的（naive）时区。

~~~python
rng = pd.date_range('3/9/2012 9:30', periods=6, freq='D')
ts = pd.Series(np.random.randn(len(rng)), index=rng)
#默认时UTC时间
ts
print(ts.index.tz)
pd.date_range('3/9/2012 9:30', periods=10, freq='D', tz='UTC')
#单纯到本地化的转换是通过tz_localize⽅法处理的
xx_ts=pd.date_range('3/9/2020 9:30', periods=6, freq='D')
ts_utc = xx_ts.tz_localize('UTC')
#上面两行类似于pd.date_range('3/9/2012 9:30', periods=10, freq='D', tz='UTC')
ts_utc.tz_convert('Asia/Shanghai')
~~~

:spider_web:tz_localize和tz_convert也是DatetimeIndex的实例⽅法。

#### 操作时区意识型Timestamp对象（Operations with Time Zone−Aware Timestamp Objects）

Timestamp对象也能被从单纯型（naive）本地化为时区意识型（time zone-aware），并从⼀个时区转换到另⼀个时区。

~~~python
stamp = pd.Timestamp('2011-03-12 04:00')
stamp_utc = stamp.tz_localize('utc')
stamp_utc.tz_convert('America/New_York')

#后面的代码我没有搞懂
stamp = pd.Timestamp('2012-11-04 00:30', tz='US/Eastern')
stamp
stamp + 2 * Hour()
#Timestamp('2012-11-04 00:30:00-0400', tz='US/Eastern')
#Timestamp('2012-11-04 01:30:00-0500', tz='US/Eastern')
~~~

#### 不同时区之间的运算（Operations Between Different Time Zones）×

两个时间序列的时区不同，在将它们合并到⼀起时，最终结果就会是UTC。

有时我们收集的数据会出现时区不一样，这个操作可以学一手。

~~~python
rng = pd.date_range('3/7/2012 9:30', periods=10, freq='B')
ts = pd.Series(np.random.randn(len(rng)), index=rng)
ts
ts1 = ts[:7].tz_localize('Europe/London')
ts2 = ts1[2:].tz_convert('Europe/Moscow')
result = ts1 + ts2
result.index
#DatetimeIndex(['2012-03-07 09:30:00+00:00', '2012-03-08 #09:30:00+00:00',
#               '2012-03-09 09:30:00+00:00', '2012-03-12 #09:30:00+00:00',
#               '2012-03-13 09:30:00+00:00', '2012-03-14 #09:30:00+00:00',
#               '2012-03-15 09:30:00+00:00'],
#            dtype='datetime64[ns, UTC]', freq='B')
~~~

:spider_web:这个可以跳过，不知道能干啥，作者说的不清楚

## 11.5 时期及其算术运算（Periods and Period Arithmetic）

时期（period）表示的是时间区间，⽐如数⽇、数⽉、数季、数年等。Period类所表示的就是这种数据类型，其构造函数需要用到⼀个字符串或整数，以及表11-4中的频率。

`p = pd.Period(2007, freq='A-DEC')` 表示2007年最后一个工作日

~~~python
p = pd.Period(2007, freq='A-DEC')
p - 2
#Period('2005', 'A-DEC')
pd.Period('2014', freq='A-DEC') - p
#<7 * YearEnds: month=12>
rng = pd.period_range('2000-01-01', '2000-06-30', freq='M')
rng
#PeriodIndex(['2000-01', '2000-02', '2000-03', '2000-04', '2000-05', '2000-06'], dtype='period[M]', freq='M')

pd.Series(np.random.randn(6), index=rng)

#有⼀个字符串数组，你也可以使⽤PeriodIndex类，作用不大吧，没啥用
values = ['2001Q3', '2002Q2', '2003Q1']
index = pd.PeriodIndex(values, freq='Q-DEC')
index
#PeriodIndex(['2001Q3', '2002Q2', '2003Q1'], dtype='period[Q-DEC]', freq='Q-DEC')
~~~

#### 时期的频率转换（Period Frequency Conversion）×

Period和PeriodIndex对象都可以通过其asfreq⽅法被转换成别的频率。

~~~python
p = pd.Period('2007', freq='A-DEC')
p
#asfreq改变p中定义的freq
p.asfreq('M', how='start')
p.asfreq('M', how='end')
#
#与上面的不一样
p = pd.Period('2007', freq='A-JUN')
p
p.asfreq('M', 'start')
#Period('2006-07', 'M')
p.asfreq('M', 'end')
#Period('2007-06', 'M')


#
rng = pd.period_range('2006', '2009', freq='A-DEC')
ts = pd.Series(np.random.randn(len(rng)), index=rng)
ts
ts.asfreq('M', how='S')
ts.asfreq('B', how='end')
~~~

:spider_web:这个好像也不太实用

#### 按季度计算的时期频率(Quarterly Period Frequencies)

**季度型数据**在会计、⾦融等领域中很常见。许多季度型数据都会涉及“财年末”的概念，通常是⼀年12个月中某月的最后⼀个⽇历⽇或⼯作⽇。

~~~python
p = pd.Period('2012Q4', freq='Q-JAN')
p4pm = (p.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60
p4pm
p4pm.to_timestamp()
#Timestamp('2012-01-30 16:00:00')
~~~

![4](F:\github_desktop\github文件路径\books\python-for-data-analysis_2nd\chapter 11 pictures\4.png)

~~~python
#要获取该季度倒数第⼆个⼯作⽇下午4点的时间戳
rng = pd.period_range('2011Q3', '2012Q4', freq='Q-JAN')
ts = pd.Series(np.arange(len(rng)), index=rng)
ts
new_rng = (rng.asfreq('B', 'e') - 1).asfreq('T', 's') + 16 * 60
ts.index = new_rng.to_timestamp()
ts
~~~

:spider_web:有点难理解:crying_cat_face:

#### 将Timestamp转换为Period（及其反向过程）Converting Timestamps to Periods (and Back)

Timestamp和Period之间的转化

使⽤to_period⽅法，可以将由**时间戳索引**的Series和DataFrame对象转换为**以时期索引**。（date-to-period）

`to_timestamp`和`to_period`

~~~python
rng = pd.date_range('1/29/2000', periods=6, freq='D')
ts2 = pd.Series(np.random.randn(6), index=rng)
ts2
ts2.to_period()
ts2.to_period('M')

pts = ts2.to_period('D')
pts
#转换为原来的D形式
pts.to_timestamp(how='end')
~~~

#### 通过数组创建PeriodIndex（Creating a PeriodIndex from Arrays）

固定频率的数据集通常会将时间信息分开存放在多个列中。宏观经济数据集中，年度和季度就分别存放在不同的列中。

~~~python
#这个宏观经济数据集中，年度和季度就分别存放在不同的列中
data = pd.read_csv('examples/macrodata.csv')
data.head(5)
data.year
data.quarter
#periodindex
index = pd.PeriodIndex(year=data.year, quarter=data.quarter,
                       freq='Q-DEC')
index
data.index = index
data.infl
#1959Q1    0.00
#1959Q2    2.34
#1959Q3    2.74
#1959Q4    0.27
#1960Q1    2.31
#          ... 
#2008Q3   -3.16
#2008Q4   -8.79
#2009Q1    0.94
#2009Q2    3.37
#2009Q3    3.56
#Freq: Q-DEC, Name: infl, Length: 203, dtype: float64
~~~

## 11.6 重采样及频率转换（Resampling and Frequency Conversion）

#### 重采样

**重采样**（resampling）指的是将时间序列从⼀个频率转换到另⼀个频率的处理过程。

将⾼频率数据聚合到低频率称为**降采样**（downsampling），⽽将低频率数据转换到⾼频率则称为**升采样**（upsampling）。

pandas对象都带有⼀个resample⽅法，它是各种频率转换⼯作的主⼒函数。resample有⼀个类似于groupby的API，调⽤resample可以分组数据，然后会调⽤⼀个聚合函数。（这样理解：resample和groupby类似）

~~~python
rng = pd.date_range('2000-01-01', periods=100, freq='D')
ts = pd.Series(np.random.randn(len(rng)), index=rng)
ts
ts.resample('M').mean()
#跟上面代码一样的功能
ts.resample('M', kind='period').mean()
~~~

#### 降采样（Downsampling）

将数据聚合到规律的低频率是⼀件⾮常普通的时间序列处理任务。待聚合的数据不必拥有固定的频率，期望的频率会⾃动定义聚合的⾯元边界，这些⾯元⽤于将时间序列拆分为多个⽚段。例如，要转换到⽉度频率（'M'或'BM'），数据需要被划分到多个单⽉时间段中。各时间段都是半开放的。⼀个数据点只能属于⼀个时间段，所有时间段的并集必须能组成整个时间帧。

两点思考：

* 各区间哪边是闭合的。
* 如何标记各个聚合⾯元，⽤区间的开头还是末尾。

~~~python
rng = pd.date_range('2000-01-01', periods=12, freq='T')
ts = pd.Series(np.arange(12), index=rng)
ts
#传⼊closed='left'会让区间以左边界闭合[)
ts.resample('5min', closed='right').sum()
#传⼊label='right'即可⽤⾯元的邮编界对其进⾏标记（]
ts.resample('5min', closed='right').sum()
ts.resample('5min', closed='right', label='right').sum()
#2000-01-01 00:00:00     0
#2000-01-01 00:05:00    15
#2000-01-01 00:10:00    40
#2000-01-01 00:15:00    11
#Freq: 5T, dtype: int32

ts.resample('5min', closed='right',
            label='right', loffset='-1s').sum()
~~~

![5](F:\github_desktop\github文件路径\books\python-for-data-analysis_2nd\chapter 11 pictures\5.png)

#### OHLC重采样(Open-High-Low-Close (OHLC) resampling)

⾦融领域中有⼀种⽆所不在的时间序列聚合⽅式，即计算各⾯元的四个值：第⼀个值（open，开盘）、最后⼀个值（close，收盘）、最⼤值（high，最⾼）以及最小值（low，最低）。传⼊how='ohlc'即可得到⼀个含有这四种聚合值的DataFrame。整个过程很⾼效，只需⼀次扫描即可计算出结果.

~~~python
ts.resample('5min').ohlc()
~~~

:spider_web:groupby中是否有这个聚合函数ohlc

#### 升采样和插值（Upsampling and Interpolation）

将数据从低频率转换到⾼频率时，就不需要聚合了。我们来看⼀个带有⼀些周型数据的DataFrame。

`asfreq`

~~~python
frame = pd.DataFrame(np.random.randn(2, 4),
                     index=pd.date_range('1/1/2000', periods=2,
                                         freq='W-WED'),
                     columns=['Colorado', 'Texas', 'New York', 'Ohio'])
frame
#当你对这个数据进⾏聚合，每组只有⼀个值，这样就会引⼊缺失值。我们使⽤asfreq⽅法转换成⾼频，不经过聚合
df_daily = frame.resample('D').asfreq()
df_daily

frame.resample('D').ffill(limit=2)
#采样，采出符合要求的数据
frame.resample('W-THU').ffill()
~~~

#### 通过时期进行重采样（Resampling with Periods）

对那些使⽤时期索引的数据进⾏重采样与时间戳很像

~~~python
frame = pd.DataFrame(np.random.randn(24, 4),
                     index=pd.period_range('1-2000', '12-2001',
                                           freq='M'),
                     columns=['Colorado', 'Texas', 'New York', 'Ohio'])
frame[:5]
#以A-DEC的标准来采集frame中的平均值
annual_frame = frame.resample('A-DEC').mean()
annual_frame
#升采样要稍微麻烦⼀些，因为你必须决定在新频率中各区间的哪端⽤于放置原来的值，就像asfreq⽅法那样。convention参数默认为'end'，可设置为'start'
# Q-DEC: Quarterly, year ending in December
annual_frame.resample('Q-DEC').ffill()
annual_frame.resample('Q-DEC', convention='end').ffill()

annual_frame.resample('Q-MAR').ffill()
~~~

:spider_web:由Q-MAR定义的时间区间只能升采样为A-MAR、A-JUN、A-SEP、A-DEC等

## 11.7 移动窗口函数（Moving Window Functions）

在移动窗口（可以带有指数衰减权数）上计算的各种统计函数也是⼀类常见于时间序列的数组变换。

可以圆滑噪⾳数据或断裂数据。我将它们称为移动窗⼝函数（moving window function），其中还包括那些窗⼝不定⻓的函数（如指数加权移动平均）。

计算扩展窗⼝平均（expanding window mean），可以使⽤expanding⽽不是rolling。“扩展”意味着，从时间序列的起始处开始窗⼝，增加窗⼝直到它超过所有的序列。

:spider_web:这一块内容我很需要

~~~python
#加载⼀些时间序列数据，将其重采样为⼯作⽇频率
close_px_all = pd.read_csv('examples/stock_px_2.csv',
                           parse_dates=True, index_col=0)
#如何在表中取三列数据
close_px = close_px_all[['AAPL', 'MSFT', 'XOM']]
#运用这些函数要填充才可以使用
#s = pd.Series([2, 3, np.nan, 10,3,4,6,9])
#s1 = s.rolling(4).mean()
#print(s1)
close_px = close_px.resample('B').ffill()
#引⼊rolling运算符，它与resample和groupby很像。
close_px.AAPL.plot()
#表达式rolling(250)与groupby很像，但不是对其进⾏分组、创建⼀个按照250天分组的滑动窗⼝对象。
close_px.AAPL.rolling(250).mean().plot()
plt.figure()

#搞金融
appl_std250 = close_px.AAPL.rolling(250, min_periods=10).std()
appl_std250[5:12]
appl_std250.plot()

#各股价60⽇均线（对数Y轴），这个可以记一下，其他不懂就算了
plt.figure()
close_px.rolling(60).mean().plot(logy=True)
#计算20天的滚动均值，第二天的按照前两天的均值来表示（不足的）
close_px.rolling('20D').mean()
~~~

:spider_web:最后两个我觉得要掌握，很重要。

#### 指数加权函数（Exponentially Weighted Functions）

使⽤固定⼤⼩窗⼝及相等权数观测值的办法是，定义⼀个衰减因⼦（decay factor）常量，以便使近期的观测值拥有更大的权数。衰减因⼦的定义⽅式有很多，⽐较流⾏的是使⽤时间间隔（span），它可以使结果兼容于窗⼝⼤⼩等于时间间隔的简单移动窗⼝（simple moving window）函数。

~~~python
close_px_all = pd.read_csv('examples/stock_px_2.csv',
                           parse_dates=True, index_col=0)
plt.figure()
aapl_px = close_px.AAPL['2006':'2007']
ma60 = aapl_px.rolling(30, min_periods=20).mean()
ewma60 = aapl_px.ewm(span=30).mean()
ma60.plot(style='k--', label='Simple MA')
ewma60.plot(style='k-', label='EW MA')
plt.legend()

#
a=aapl_px.rolling(30, min_periods=20).mean()[:25]
#下面代码无NA
b=aapl_px.ewm(span=30).mean()[:25]
a,b
~~~

#### 二元移动窗口函数（Binary Moving Window Functions）



~~~python
close_px_all = pd.read_csv('examples/stock_px_2.csv',
                           parse_dates=True, index_col=0)
plt.figure()
spx_px = close_px_all['SPX']
#时间序列的百分数变化
spx_rets = spx_px.pct_change()
returns = close_px.pct_change()
corr = returns.AAPL.rolling(125, min_periods=100).corr(spx_rets)
corr.plot()

plt.figure()
corr = returns.rolling(125, min_periods=100).corr(spx_rets)
corr.plot()
~~~

#### 用户定义的移动窗口函数（User-Defined Moving Window Functions）

rolling_apply函数使你能够在移动窗⼝上应⽤⾃⼰设计的数组函数。唯⼀要求的就是：该函数要能从数组的各个⽚段中产⽣单个值（即约简）。⽐如说，当我们⽤rolling(...).quantile(q)计算样本分位数时，可能对样本中特定值的百分等级感兴趣。scipy.stats.percentileofscore函数就能达到这个⽬的。

~~~python
plt.figure()
from scipy.stats import percentileofscore
score_at_2percent = lambda x: percentileofscore(x, 0.02)
result = returns.AAPL.rolling(250).apply(score_at_2percent)
result.plot()
~~~

