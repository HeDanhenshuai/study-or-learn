[toc]

pandas是数据清洗和数据分析的数据结构操作工具，pandas是在numpy中的array上构建的，特别是基于数组的函数和不使用for循环的数据处理。但是二者最大的不同是pandas是**专门处理表格和混杂数据设计**的，而numpy更适合**处理统一的数值数组数据**。

# 第五章 pandas入门

## pandas数据结构介绍

#### Series

* `Series`类似于⼀维数组的对象。仅由⼀组数据即可产⽣最简单的Series。主要是**Series 的values和index属性**获取其数组表示形式和索引对象。
* 与普通`NumPy`数组相⽐，你可以通过**索引**的⽅式选取Series中的单个或⼀组值。在用numpy做操作的时候，可以保留索引值。
* `Series`是索引值到数据值的一个映射，它由⼀组数据（各种NumPy数据类型）以及⼀组与之相关的数据标签（即索引）组成。
* 字典可创建`Series`。修改键值（传入新的index）来改变顺序。
* pandas中通过`isnull`和`notnull`来检测缺失数据。（**第七章详谈**）
* `Series`对象本身及其索引都有⼀个`name`属性，==该属性跟pandas其他的关键功能关系⾮常密切==。

#### DataFrame

* 表格型数据结构（数值、字符串、布尔值等）。
* 行（`index`，我经常碰到的时间序列）列（`columns`，我之前一直叫列头）索引
* `head`（）选取前五列
* 指定列序，则DataFrame的列就会按照指定顺序进⾏排列。
* 位置属性来获取值（`loc`和`iloc`）
* 赋值更改

>data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],\
        'year': [2000, 2001, 2002, 2001, 2002, 2003],\
        'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}
frame = pd.DataFrame(data)

      frame2 = pd.DataFrame(data, columns=['year', 'state', 'pop', 'debt'], index=['one', 'two', 'three', 'four','five', 'six'])
      
      frame2['debt'] = np.arange(6.) #赋值直接更改

* 精准填充

> val = pd.Series([-1.2, -1.5, -1.7], index=['two', 'four', 'five'])
> frame2['debt'] = val

* 为不存在的列赋值会创建出⼀个新列。

> frame2['eastern'] = frame2.state == 'Ohio'#可以学一手，记一下就行，这种操作也不常用啊

* ==源修改==(以上操作全都在原表上的操作)；若不在原表上操作，就需要**copy**一份

> del frame2['eastern']#`del`删除列
> frame2.columns

___

* 嵌套字典传给DataFrame，pandas就会被解释为：外层字典的键作为列索引（columns），内层键则作为⾏索引（index）

> pop = {'Nevada': {2001: 2.4, 2002: 2.9}, 'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}
>
> frame3 = pd.DataFrame(pop)
> frame3
>
> frame3.T #转置

* **`values`**将DataFrame转化为np.array，后面就可以进行numpy数组操作了！

#### 索引对象

pandas的索引对象负责管理轴标签和其他元数据（⽐如轴名称等）。**Index对象不可变**

* index可重复

#### 重要功能

* **重新索引`reindex`**。(method='ffill')使⽤ffill可以实现**前向值填充**。

> obj3 = pd.Series(['blue', 'purple', 'yellow'], index=[0, 2, 4])
> obj3
> obj3.reindex(range(6), method='ffill')

* 丢弃指定轴上的项（`drop`）传递`axis=1`或`axis`='columns'可以删除列的值

> 在设置相关要求时**inplace=True** ⼩⼼使⽤inplace，它会销毁所有被删除的数据。

#### 索引、选取和过滤

* 第一种方式：直接按照**行列索引、[:3]**这种方式来找值

> data = pd.DataFrame(np.arange(16).reshape((4, 4)),index=['Ohio', 'Colorado', 'Utah', 'New York'],columns=['one', 'two', 'three','four'])
>
> data[data < 5] = 0#过滤选取值data<5直接是找表中的值小于5

* 第二种方式：用`loc[]`和`iloc[]`来进行选取

> data.loc['Colorado', ['two', 'three']]# 根据行列索引来找值（excel操作） 
>
> data.iloc[[1, 2], [3, 0, 1]]#同上类似操作

#### 整数索引

* 所以开发者强烈要求使用`loc[]`和`iloc[]`

#### 算术运算和数据对齐（重要功能：对不同索引的对象进行算数运算）

* ⾃动的数据对⻬操作在不重叠的索引处引⼊了NA值。**两个DataFrame和Series可以使用算术运算**

#### 在算术方法中填充值

* 将它们相加时，**没有重叠的位置就会产⽣NA值**。

| 算术方法 |      说明      |
| :------: | :------------: |
| add,radd | 用于加法的操作 |
| sub,rsub | 用于减法的操作 |
| mul,rmul | 用于乘法的操作 |
| div.rdiv | 用于除法的操作 |
| pow,rpow |    指数运算    |



> df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)),columns=list('abcd'))
> df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)),columns=list('abcde'))
>
> df1.add(df2, fill_value=0)
>
> df1.reindex(columns=df2.columns, fill_value=0) # 关注reindex方法

:spider_web:注意add和reindex都有fill_value这一属性。

#### DataFrame和Series之间的运算（两者有明确规定）

* 下面实例(**广播机制**(每一行都执行这种操作))

> #np中array中的广播机制
>
> arr = np.arange(12.).reshape((3, 4))
> arr
> arr[0]
> arr - arr[0]
>
> #——————————————————————————————
>
> #pandas中DataFrame和Series的广播机制
>
> frame = pd.DataFrame(np.arange(12.).reshape((4, 3)),
>                      columns=list('bde'),
>                      index=['Utah', 'Ohio', 'Texas', 'Oregon'])
> series = frame.iloc[0]
>
> frame - series
>
> #——————————————————————————————列上广播操作
>
> frame = pd.DataFrame(np.arange(12.).reshape((4, 3)),\
>                      columns=list('bde'),\
>                      index=['Utah', 'Ohio', 'Texas', 'Oregon'])
> series = frame.iloc[:,0]
> print((frame.T - series).T)

* 下面是分别实现行和列的广播机制小例子

> frame = pd.DataFrame(np.arange(12.).reshape((4, 3)),\
>
> ​                     columns=list('bde'),\
>
> ​                     index=['Utah', 'Ohio', 'Texas', 'Oregon'])
>
> series=frame.iloc[0]
>
> series3 = frame['d']
>
> print(frame.sub(series, axis='columns'))
>
> print(frame.sub(series3,axis='index'))

#### 补充知识点：pandas向numpy之间的转换

> arr= pd.Series([1.5, -2.5, 0])
> np__ar=arr.values               #values就可以实现，然后就可以进行数组运算

#### 函数应用和映射

* apply方法

> #该功能可以在一个数据表中找到一列（columns）中的最大值和最小值。
>
> frame = pd.DataFrame(np.random.randn(4, 3), columns=list('bde'),index=['Utah', 'Ohio', 'Texas', 'Oregon'])
>
> f = lambda x: x.max() - x.min()
>
> frame.apply(f)
>
> frame.apply(f, axis='columns')
>
> #该功能实现找到数据表中每一列的最大值和最小值，然后形成一个DataFrame
>
> def f(x):
>     return pd.Series([x.min(), x.max()], index=['min', 'max'])
> frame.apply(f)
>
> #格式化字符串
>
> format = lambda x: '%.2f' % x
>
> frame.applymap(format)  #applymap 用于dataframe上，是**元素级别的操作**；
>
> frame['e'].map(format) #map 用于series上，是**元素级别的操作**。

:spider_web:补充：许多常用的数组统计功能都被实现成DataFrame的方法（sum和mean），因此有时候无需使用apply方法

#### 排序和排名

* 根据条件对数据集**排序（sorting）**
  * `sort_index()`和 `sort_values()`

> #————————————sort_index()的用法
>
> frame = pd.DataFrame(np.arange(8).reshape((2, 4)),\
>
> ​                     index=['three', 'one'],\
>
> ​                     columns=['d', 'a', 'b', 'c'])
>
> frame.sort_index()
>
> frame.sort_index(axis=1,ascending=False)
>
> #————————————sort_values()的用法
>
> frame = pd.DataFrame({'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]})
> frame.sort_values(by='b')

* 根据条件对数据集**排名（rank）**

>obj = pd.Series([7, -5, 7, 4, 2, 0, 4])
>obj.rank()
>
>obj.rank(method='first')
>
>obj.rank(ascending=False, method='max') #降序排名
>
>frame = pd.DataFrame({'b': [4.3, 7, -3, 2], 'a': [0, 1, 0, 1],\
>                      'c': [-2, 5, 8, -2.5]})
>frame.rank(axis='columns')

| 方法（method） |               说明               |
| :------------: | :------------------------------: |
|      min       |       使用分组中的最小排名       |
|      max       |       使用分组中的最大排名       |
|     first      | 值在原始数据中的出现顺序分配排名 |

#### 带有重复标签的轴索引

> obj = pd.Series(range(5), index=['a', 'a', 'b', 'b', 'c'])
>
> obj.index.is_unique #查看索引是否唯一，返回布尔值
>
> df.mean(axis='columns', skipna=False)

#### 汇总和计算描述统计(常见的数理统计的一些参数)

> df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5],\
>                    [np.nan, np.nan], [0.75, -1.3]],\
>                   index=['a', 'b', 'c', 'd'],\
>                   columns=['one', 'two'])
> #————————约简型
> df.sum()
> df.sum(axis='columns')
> df.mean(axis='columns', skipna=False)
> #————————
> df.idxmax() #切分数据表，可以找到每一区域内的最大的数据点（返回的是间接统计（如达到最值的索引））
> df.idxmin() #切分数据表，可以找到每一区域内的最小的数据点（返回的是间接统计（如达到最值的索引））
> #————————累计型
> df.cumsum() #累计值
> #————————汇总统计
> df.describe() #描述信息

* 约简方法表

|  选项  |            说明            |
| :----: | :------------------------: |
|  axis  | 约简的轴，0代表行，1代表列 |
| skipna |   排除缺失值，默认为True   |

* 描述和汇总统计

|      方法      |                      说明                      |
| :------------: | :--------------------------------------------: |
|   **count**    |                  非NA值的数量                  |
|  **describe**  |     针对Series或各DataFrame列计算汇总统计      |
|    min，max    |             **计算最大值和最小值**             |
| argmin，argmax | **计算获取到最小值和最大值的索引位置（整数）** |
| idxmin，idxmax |    **计算能够获取到最小值和最大值的索引值**    |
|    quantile    |            计算样本的分位数（0到1）            |
|      sum       |                    值的总和                    |
|      mean      |                 **值的平均数**                 |
|     median     |        **值的算术中位数（50%分位数）**         |
|      mad       |         **根据平均值计算平均绝对离差**         |
|      var       |                **样本值的方差**                |
|      std       |               **样本值的标准差**               |
|      skew      |             样本值的偏度（三阶矩）             |
|      kurt      |             样本值的峰度（四阶矩）             |
|     cumsum     |                 样本值的累计和                 |
| cummin、cummax |         样本值的累计最大值和累计最小值         |
|    cumprod     |                 样本值的累计积                 |
|      diff      |        计算一阶差分（对时间序列很有用）        |
|   pct_change   |                 计算百分数变化                 |

:spider_web:其中describe（）列举了count、mean、std、min、25%、50%、75%、max等信息。

:spider_web:argmin()是numpy的操作。

#### 相关系数和协方差

* 此处涉及到pickle操作、时间序列中DataFrame.pct_change()、head()、tail()
* corr()、cov()、corrwith()

> price = pd.read_pickle('examples/yahoo_price.pkl')
> volume = pd.read_pickle('examples/yahoo_volume.pkl')
> returns = price.pct_change()
> print(returns.tail())
> print(returns['MSFT'].corr(returns['IBM']))
> print(returns['MSFT'].cov(returns['IBM']))
> print(returns.corr())
> print(returns.cov())
> print(returns.corrwith(returns.IBM))

#### 唯⼀值、值计数以及成员资格

* 唯一值 unique()
* 值计数value_counts()
* isin()⽤于判断⽮量化集合的成员资格，可⽤于过滤Series中或DataFrame列中数据的⼦集。
* isin() 类似方法Index.get_indexer()给你⼀个索引数组，从可能包含重复值的数组到另⼀个不同值的数组

> obj = pd.Series(['c', 'a', 'd', 'a', 'a', 'b', 'b', 'c', 'c'])
> pd.value_counts(obj.values, sort=False)
> print(obj[obj.isin(['b', 'c'])].index)
> to_match = pd.Series(['c', 'a', 'b', 'b', 'c', 'a'])
> unique_vals=to_match.unique()
> print(pd.Index(unique_vals).get_indexer(to_match))

|     方法     |                          说明                           |
| :----------: | :-----------------------------------------------------: |
|     isin     |                     两series找位置                      |
|    match     |   两series找位置,对于数据对齐和连接类型的操作十分有用   |
|    unique    |                按发现顺序返回唯一值数组                 |
| value_counts | 返回series,索引唯一,值为频率,默认为降序排列(sort可更改) |

#### 补充内容：柱状图的绘制

> data = pd.DataFrame({'Qu1': [1, 3, 4, 3, 4],\
>                      'Qu2': [2, 3, np.nan, 2, 7],\
>                      'Qu3': [1, 5, 2, 4, 4]})
> result = data.apply(pd.value_counts).fillna(0)

# 第六章 数据载入、存储及文件格式 





# 第七章 数据清洗与准备







# 第八章 数据规整：连接、联合与重塑







# 第十章 数据聚合和分组操作







# 第十一章 时间序列







# 第十二章 高阶pandas









# 第十四章 数据分析示例